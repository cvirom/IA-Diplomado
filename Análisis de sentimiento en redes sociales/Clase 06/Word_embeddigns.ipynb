{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Word embeddigns.ipynb",
      "provenance": [],
      "toc_visible": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "84EgEDmmri2j",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "sns.set()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BOXqVdvjsNwl",
        "colab_type": "code",
        "outputId": "4fd481e5-050c-40ee-b38e-1d421b736d11",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 55
        }
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lu9SMVRgs8ob",
        "colab_type": "text"
      },
      "source": [
        "# 1. Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NiDOA4VmsNzy",
        "colab_type": "code",
        "outputId": "65891483-ff91-4b25-d1af-82beea356133",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        }
      },
      "source": [
        "df_disaster = pd.read_csv('train.csv')\n",
        "df_disaster.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(7613, 5)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v9QcXvtJvf4z",
        "colab_type": "code",
        "outputId": "637d3554-faa3-451f-9096-49f250b25f7e",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 92
        }
      },
      "source": [
        "!python -m spacy download en_core_web_md"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: en_core_web_md==2.1.0 from https://github.com/explosion/spacy-models/releases/download/en_core_web_md-2.1.0/en_core_web_md-2.1.0.tar.gz#egg=en_core_web_md==2.1.0 in /usr/local/lib/python3.6/dist-packages (2.1.0)\n",
            "\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n",
            "You can now load the model via spacy.load('en_core_web_md')\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrJjWrxTxRuK",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(df_disaster['text'], df_disaster['target'], test_size=0.2)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OcGQksGjwUIN",
        "colab_type": "text"
      },
      "source": [
        "# 2. Spacy word vectors"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "m7JsSkeQxdpb",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import spacy\n",
        "nlp = spacy.load(\"en_core_web_md\")\n",
        "\n",
        "def display_vectors(text):\n",
        "  doc = nlp(text)\n",
        "  for token in doc:\n",
        "    print(token.text, token.has_vector, token.vector_norm, token.is_oov)\n",
        "\n",
        "def get_vector(text):\n",
        "  doc = nlp(text)\n",
        "  return doc.vector #average of the token vectors."
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VG6FDBzWFU2B",
        "colab_type": "code",
        "outputId": "0020f129-cf40-4f36-fd37-15884509a679",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 90
        }
      },
      "source": [
        "print(nlp('man').similarity(nlp('woman')))\n",
        "print(nlp('king').similarity(nlp('queen')))\n",
        "print(nlp('actor').similarity(nlp('actress')))\n",
        "print(nlp('doctor').similarity(nlp('nurse')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7401744538491297\n",
            "0.7252610345406867\n",
            "0.7484467528753997\n",
            "0.6880643786881521\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "l0u2BiotFkg4",
        "colab_type": "code",
        "outputId": "ea2252e7-7248-4b78-ef80-f0bd62f91a6a",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 72
        }
      },
      "source": [
        "print(nlp('france').similarity(nlp('paris')))\n",
        "print(nlp('japan').similarity(nlp('tokyo')))\n",
        "print(nlp('usa').similarity(nlp('la')))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.7916328323319856\n",
            "0.800706948877685\n",
            "0.24974637037031683\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dniVSy85wRpc",
        "colab_type": "code",
        "outputId": "07029c58-1a8c-4c17-f694-d51e19eb3d01",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        }
      },
      "source": [
        "display_vectors(df_disaster['text'].iloc[3587])"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Winnipeg True 6.459667 False\n",
            "police True 7.3889823 False\n",
            "seek True 5.802574 False\n",
            "witnesses True 6.5771213 False\n",
            "in True 5.0929856 False\n",
            "Arlington True 6.3564496 False\n",
            "and True 4.6577983 False\n",
            "William True 6.7178607 False\n",
            "fatal True 6.661328 False\n",
            "crash True 6.6807313 False\n",
            "http://t.co/N2bCf4M64V False 0.0 True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-P9vM05wBaPE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "X_train_we = X_train.apply(get_vector)\n",
        "X_val_we = X_val.apply(get_vector)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VnjSIL-xBa8y",
        "colab_type": "code",
        "outputId": "195777a3-b072-4c44-a793-3940c17042af",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "X_train_we = pd.DataFrame(X_train_we.tolist())\n",
        "X_val_we = pd.DataFrame(X_val_we.tolist())\n",
        "X_train_we.shape, X_val_we.shape"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((6090, 300), (1523, 300))"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fiBqeGSQDo9g",
        "colab_type": "code",
        "outputId": "385ab03f-c4ff-4c7e-87e4-f8a0c1d6a8f8",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        }
      },
      "source": [
        "X_train_we.sample(5)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>10</th>\n",
              "      <th>11</th>\n",
              "      <th>12</th>\n",
              "      <th>13</th>\n",
              "      <th>14</th>\n",
              "      <th>15</th>\n",
              "      <th>16</th>\n",
              "      <th>17</th>\n",
              "      <th>18</th>\n",
              "      <th>19</th>\n",
              "      <th>20</th>\n",
              "      <th>21</th>\n",
              "      <th>22</th>\n",
              "      <th>23</th>\n",
              "      <th>24</th>\n",
              "      <th>25</th>\n",
              "      <th>26</th>\n",
              "      <th>27</th>\n",
              "      <th>28</th>\n",
              "      <th>29</th>\n",
              "      <th>30</th>\n",
              "      <th>31</th>\n",
              "      <th>32</th>\n",
              "      <th>33</th>\n",
              "      <th>34</th>\n",
              "      <th>35</th>\n",
              "      <th>36</th>\n",
              "      <th>37</th>\n",
              "      <th>38</th>\n",
              "      <th>39</th>\n",
              "      <th>...</th>\n",
              "      <th>260</th>\n",
              "      <th>261</th>\n",
              "      <th>262</th>\n",
              "      <th>263</th>\n",
              "      <th>264</th>\n",
              "      <th>265</th>\n",
              "      <th>266</th>\n",
              "      <th>267</th>\n",
              "      <th>268</th>\n",
              "      <th>269</th>\n",
              "      <th>270</th>\n",
              "      <th>271</th>\n",
              "      <th>272</th>\n",
              "      <th>273</th>\n",
              "      <th>274</th>\n",
              "      <th>275</th>\n",
              "      <th>276</th>\n",
              "      <th>277</th>\n",
              "      <th>278</th>\n",
              "      <th>279</th>\n",
              "      <th>280</th>\n",
              "      <th>281</th>\n",
              "      <th>282</th>\n",
              "      <th>283</th>\n",
              "      <th>284</th>\n",
              "      <th>285</th>\n",
              "      <th>286</th>\n",
              "      <th>287</th>\n",
              "      <th>288</th>\n",
              "      <th>289</th>\n",
              "      <th>290</th>\n",
              "      <th>291</th>\n",
              "      <th>292</th>\n",
              "      <th>293</th>\n",
              "      <th>294</th>\n",
              "      <th>295</th>\n",
              "      <th>296</th>\n",
              "      <th>297</th>\n",
              "      <th>298</th>\n",
              "      <th>299</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>5081</th>\n",
              "      <td>-0.081516</td>\n",
              "      <td>0.137667</td>\n",
              "      <td>0.047158</td>\n",
              "      <td>-0.066955</td>\n",
              "      <td>0.117892</td>\n",
              "      <td>0.100264</td>\n",
              "      <td>0.176085</td>\n",
              "      <td>-0.085922</td>\n",
              "      <td>0.002362</td>\n",
              "      <td>0.975046</td>\n",
              "      <td>-0.164599</td>\n",
              "      <td>-0.042957</td>\n",
              "      <td>-0.047453</td>\n",
              "      <td>-0.136181</td>\n",
              "      <td>-0.110070</td>\n",
              "      <td>-0.041855</td>\n",
              "      <td>-0.253748</td>\n",
              "      <td>1.235979</td>\n",
              "      <td>0.115536</td>\n",
              "      <td>0.040104</td>\n",
              "      <td>-0.123364</td>\n",
              "      <td>-0.004240</td>\n",
              "      <td>-0.069473</td>\n",
              "      <td>-0.255940</td>\n",
              "      <td>-0.173225</td>\n",
              "      <td>0.238471</td>\n",
              "      <td>-0.161529</td>\n",
              "      <td>-0.072304</td>\n",
              "      <td>0.034037</td>\n",
              "      <td>0.130991</td>\n",
              "      <td>-0.017803</td>\n",
              "      <td>0.093638</td>\n",
              "      <td>-0.082729</td>\n",
              "      <td>0.201306</td>\n",
              "      <td>-0.071427</td>\n",
              "      <td>-0.116918</td>\n",
              "      <td>0.098256</td>\n",
              "      <td>-0.018394</td>\n",
              "      <td>-0.031072</td>\n",
              "      <td>-0.036375</td>\n",
              "      <td>...</td>\n",
              "      <td>0.144326</td>\n",
              "      <td>0.000561</td>\n",
              "      <td>-0.058697</td>\n",
              "      <td>0.205520</td>\n",
              "      <td>0.116389</td>\n",
              "      <td>-0.088574</td>\n",
              "      <td>0.153458</td>\n",
              "      <td>0.139711</td>\n",
              "      <td>-0.010943</td>\n",
              "      <td>0.020584</td>\n",
              "      <td>-0.260560</td>\n",
              "      <td>0.104517</td>\n",
              "      <td>-0.081950</td>\n",
              "      <td>0.007560</td>\n",
              "      <td>-0.130997</td>\n",
              "      <td>0.107563</td>\n",
              "      <td>-0.021327</td>\n",
              "      <td>-0.090975</td>\n",
              "      <td>0.011279</td>\n",
              "      <td>0.061167</td>\n",
              "      <td>-0.116290</td>\n",
              "      <td>-0.000994</td>\n",
              "      <td>0.185405</td>\n",
              "      <td>0.059160</td>\n",
              "      <td>0.035380</td>\n",
              "      <td>0.027707</td>\n",
              "      <td>0.023836</td>\n",
              "      <td>0.036571</td>\n",
              "      <td>0.013080</td>\n",
              "      <td>-0.097502</td>\n",
              "      <td>-0.093522</td>\n",
              "      <td>0.022787</td>\n",
              "      <td>0.118051</td>\n",
              "      <td>-0.153704</td>\n",
              "      <td>0.208844</td>\n",
              "      <td>-0.169311</td>\n",
              "      <td>-0.004759</td>\n",
              "      <td>-0.082663</td>\n",
              "      <td>-0.114555</td>\n",
              "      <td>0.004344</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5758</th>\n",
              "      <td>-0.052561</td>\n",
              "      <td>0.190063</td>\n",
              "      <td>-0.074788</td>\n",
              "      <td>-0.053283</td>\n",
              "      <td>0.029875</td>\n",
              "      <td>-0.090220</td>\n",
              "      <td>0.086876</td>\n",
              "      <td>-0.115823</td>\n",
              "      <td>0.003757</td>\n",
              "      <td>1.966864</td>\n",
              "      <td>-0.193011</td>\n",
              "      <td>-0.024046</td>\n",
              "      <td>0.128216</td>\n",
              "      <td>-0.023825</td>\n",
              "      <td>-0.059378</td>\n",
              "      <td>-0.034237</td>\n",
              "      <td>-0.077747</td>\n",
              "      <td>0.780934</td>\n",
              "      <td>-0.072087</td>\n",
              "      <td>-0.097178</td>\n",
              "      <td>-0.019426</td>\n",
              "      <td>-0.066290</td>\n",
              "      <td>-0.036386</td>\n",
              "      <td>0.065460</td>\n",
              "      <td>0.119368</td>\n",
              "      <td>0.067731</td>\n",
              "      <td>-0.011317</td>\n",
              "      <td>-0.002829</td>\n",
              "      <td>0.078162</td>\n",
              "      <td>-0.009719</td>\n",
              "      <td>-0.031576</td>\n",
              "      <td>0.052267</td>\n",
              "      <td>0.048697</td>\n",
              "      <td>0.049100</td>\n",
              "      <td>0.011517</td>\n",
              "      <td>0.009192</td>\n",
              "      <td>-0.182388</td>\n",
              "      <td>0.095615</td>\n",
              "      <td>-0.064754</td>\n",
              "      <td>0.066247</td>\n",
              "      <td>...</td>\n",
              "      <td>0.011589</td>\n",
              "      <td>0.137030</td>\n",
              "      <td>-0.017862</td>\n",
              "      <td>0.113407</td>\n",
              "      <td>0.083130</td>\n",
              "      <td>-0.097887</td>\n",
              "      <td>0.136377</td>\n",
              "      <td>0.057883</td>\n",
              "      <td>0.211631</td>\n",
              "      <td>-0.130025</td>\n",
              "      <td>0.000009</td>\n",
              "      <td>-0.019518</td>\n",
              "      <td>-0.110055</td>\n",
              "      <td>-0.084601</td>\n",
              "      <td>0.009046</td>\n",
              "      <td>0.034520</td>\n",
              "      <td>0.056147</td>\n",
              "      <td>0.182896</td>\n",
              "      <td>-0.119569</td>\n",
              "      <td>0.210105</td>\n",
              "      <td>0.091271</td>\n",
              "      <td>0.017967</td>\n",
              "      <td>0.036955</td>\n",
              "      <td>-0.001079</td>\n",
              "      <td>0.057208</td>\n",
              "      <td>0.073697</td>\n",
              "      <td>0.050998</td>\n",
              "      <td>0.043460</td>\n",
              "      <td>0.026884</td>\n",
              "      <td>0.067419</td>\n",
              "      <td>-0.169350</td>\n",
              "      <td>0.007242</td>\n",
              "      <td>0.017733</td>\n",
              "      <td>-0.133195</td>\n",
              "      <td>-0.002906</td>\n",
              "      <td>-0.020693</td>\n",
              "      <td>-0.127250</td>\n",
              "      <td>0.007629</td>\n",
              "      <td>-0.010521</td>\n",
              "      <td>0.036336</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1682</th>\n",
              "      <td>0.140874</td>\n",
              "      <td>-0.029021</td>\n",
              "      <td>-0.049915</td>\n",
              "      <td>-0.120664</td>\n",
              "      <td>0.127636</td>\n",
              "      <td>0.020661</td>\n",
              "      <td>0.015689</td>\n",
              "      <td>0.156856</td>\n",
              "      <td>-0.135592</td>\n",
              "      <td>1.186285</td>\n",
              "      <td>-0.239191</td>\n",
              "      <td>-0.120886</td>\n",
              "      <td>0.033742</td>\n",
              "      <td>0.019426</td>\n",
              "      <td>-0.106772</td>\n",
              "      <td>-0.035390</td>\n",
              "      <td>0.036074</td>\n",
              "      <td>0.823016</td>\n",
              "      <td>-0.045634</td>\n",
              "      <td>-0.070333</td>\n",
              "      <td>0.121116</td>\n",
              "      <td>-0.098424</td>\n",
              "      <td>0.082502</td>\n",
              "      <td>-0.095856</td>\n",
              "      <td>0.096756</td>\n",
              "      <td>-0.067063</td>\n",
              "      <td>-0.164492</td>\n",
              "      <td>0.075859</td>\n",
              "      <td>-0.092799</td>\n",
              "      <td>0.191781</td>\n",
              "      <td>0.140146</td>\n",
              "      <td>0.071680</td>\n",
              "      <td>-0.126514</td>\n",
              "      <td>0.005881</td>\n",
              "      <td>0.021060</td>\n",
              "      <td>-0.021668</td>\n",
              "      <td>0.050026</td>\n",
              "      <td>0.182197</td>\n",
              "      <td>-0.067946</td>\n",
              "      <td>0.061699</td>\n",
              "      <td>...</td>\n",
              "      <td>0.063373</td>\n",
              "      <td>0.026776</td>\n",
              "      <td>-0.059228</td>\n",
              "      <td>0.191199</td>\n",
              "      <td>-0.048139</td>\n",
              "      <td>-0.095516</td>\n",
              "      <td>-0.030908</td>\n",
              "      <td>0.101950</td>\n",
              "      <td>-0.057712</td>\n",
              "      <td>-0.013521</td>\n",
              "      <td>-0.247572</td>\n",
              "      <td>0.023582</td>\n",
              "      <td>0.055709</td>\n",
              "      <td>0.126077</td>\n",
              "      <td>0.128854</td>\n",
              "      <td>0.016681</td>\n",
              "      <td>0.023398</td>\n",
              "      <td>-0.159658</td>\n",
              "      <td>-0.089787</td>\n",
              "      <td>-0.136099</td>\n",
              "      <td>-0.089266</td>\n",
              "      <td>-0.016581</td>\n",
              "      <td>-0.102863</td>\n",
              "      <td>-0.023974</td>\n",
              "      <td>0.061990</td>\n",
              "      <td>0.020311</td>\n",
              "      <td>0.097904</td>\n",
              "      <td>-0.003077</td>\n",
              "      <td>0.042361</td>\n",
              "      <td>0.033723</td>\n",
              "      <td>-0.026470</td>\n",
              "      <td>-0.026463</td>\n",
              "      <td>-0.017024</td>\n",
              "      <td>0.048407</td>\n",
              "      <td>-0.043280</td>\n",
              "      <td>-0.071264</td>\n",
              "      <td>-0.056487</td>\n",
              "      <td>0.040557</td>\n",
              "      <td>-0.140717</td>\n",
              "      <td>0.082089</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5494</th>\n",
              "      <td>-0.227624</td>\n",
              "      <td>0.187711</td>\n",
              "      <td>-0.014611</td>\n",
              "      <td>0.163355</td>\n",
              "      <td>0.060943</td>\n",
              "      <td>0.011739</td>\n",
              "      <td>-0.039890</td>\n",
              "      <td>-0.087764</td>\n",
              "      <td>-0.131447</td>\n",
              "      <td>1.483381</td>\n",
              "      <td>-0.268507</td>\n",
              "      <td>-0.087014</td>\n",
              "      <td>-0.098206</td>\n",
              "      <td>-0.018229</td>\n",
              "      <td>-0.350477</td>\n",
              "      <td>-0.141304</td>\n",
              "      <td>-0.078607</td>\n",
              "      <td>1.083124</td>\n",
              "      <td>0.043478</td>\n",
              "      <td>-0.068898</td>\n",
              "      <td>0.076843</td>\n",
              "      <td>-0.022701</td>\n",
              "      <td>0.076501</td>\n",
              "      <td>0.110489</td>\n",
              "      <td>0.010406</td>\n",
              "      <td>-0.048846</td>\n",
              "      <td>-0.047487</td>\n",
              "      <td>0.001894</td>\n",
              "      <td>0.048635</td>\n",
              "      <td>0.175835</td>\n",
              "      <td>-0.143004</td>\n",
              "      <td>-0.049379</td>\n",
              "      <td>-0.023022</td>\n",
              "      <td>0.049530</td>\n",
              "      <td>-0.063634</td>\n",
              "      <td>0.078642</td>\n",
              "      <td>-0.056384</td>\n",
              "      <td>0.044472</td>\n",
              "      <td>0.061755</td>\n",
              "      <td>0.272416</td>\n",
              "      <td>...</td>\n",
              "      <td>0.098965</td>\n",
              "      <td>0.131487</td>\n",
              "      <td>-0.009691</td>\n",
              "      <td>-0.027884</td>\n",
              "      <td>-0.013798</td>\n",
              "      <td>-0.200838</td>\n",
              "      <td>-0.029467</td>\n",
              "      <td>0.046903</td>\n",
              "      <td>-0.072245</td>\n",
              "      <td>-0.052238</td>\n",
              "      <td>0.103558</td>\n",
              "      <td>0.051460</td>\n",
              "      <td>0.067216</td>\n",
              "      <td>-0.018100</td>\n",
              "      <td>0.089859</td>\n",
              "      <td>0.020468</td>\n",
              "      <td>-0.024731</td>\n",
              "      <td>0.163648</td>\n",
              "      <td>-0.068588</td>\n",
              "      <td>0.023303</td>\n",
              "      <td>-0.054314</td>\n",
              "      <td>-0.014147</td>\n",
              "      <td>0.071747</td>\n",
              "      <td>-0.065753</td>\n",
              "      <td>0.186291</td>\n",
              "      <td>0.100535</td>\n",
              "      <td>0.010419</td>\n",
              "      <td>0.023661</td>\n",
              "      <td>-0.069279</td>\n",
              "      <td>-0.187720</td>\n",
              "      <td>-0.157786</td>\n",
              "      <td>-0.116714</td>\n",
              "      <td>0.108426</td>\n",
              "      <td>-0.073736</td>\n",
              "      <td>-0.003172</td>\n",
              "      <td>-0.225751</td>\n",
              "      <td>-0.055872</td>\n",
              "      <td>-0.158389</td>\n",
              "      <td>-0.114203</td>\n",
              "      <td>0.151461</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5955</th>\n",
              "      <td>-0.163305</td>\n",
              "      <td>0.131606</td>\n",
              "      <td>-0.017082</td>\n",
              "      <td>0.004019</td>\n",
              "      <td>-0.093206</td>\n",
              "      <td>-0.003892</td>\n",
              "      <td>-0.021231</td>\n",
              "      <td>-0.166458</td>\n",
              "      <td>0.020036</td>\n",
              "      <td>1.166113</td>\n",
              "      <td>-0.013922</td>\n",
              "      <td>0.253742</td>\n",
              "      <td>0.127557</td>\n",
              "      <td>-0.053482</td>\n",
              "      <td>0.007639</td>\n",
              "      <td>0.057512</td>\n",
              "      <td>-0.057403</td>\n",
              "      <td>1.222748</td>\n",
              "      <td>-0.219217</td>\n",
              "      <td>-0.144139</td>\n",
              "      <td>-0.142976</td>\n",
              "      <td>-0.112124</td>\n",
              "      <td>-0.117768</td>\n",
              "      <td>0.055310</td>\n",
              "      <td>0.150681</td>\n",
              "      <td>0.113004</td>\n",
              "      <td>-0.029543</td>\n",
              "      <td>-0.068641</td>\n",
              "      <td>0.122258</td>\n",
              "      <td>0.047280</td>\n",
              "      <td>-0.077243</td>\n",
              "      <td>-0.052187</td>\n",
              "      <td>-0.086145</td>\n",
              "      <td>0.070125</td>\n",
              "      <td>-0.047727</td>\n",
              "      <td>-0.001461</td>\n",
              "      <td>0.033768</td>\n",
              "      <td>0.255867</td>\n",
              "      <td>-0.021139</td>\n",
              "      <td>0.131784</td>\n",
              "      <td>...</td>\n",
              "      <td>0.183380</td>\n",
              "      <td>0.127509</td>\n",
              "      <td>0.047511</td>\n",
              "      <td>0.043675</td>\n",
              "      <td>0.011609</td>\n",
              "      <td>-0.180713</td>\n",
              "      <td>-0.084524</td>\n",
              "      <td>0.036081</td>\n",
              "      <td>0.469995</td>\n",
              "      <td>-0.040710</td>\n",
              "      <td>-0.013356</td>\n",
              "      <td>-0.054351</td>\n",
              "      <td>-0.100465</td>\n",
              "      <td>-0.050523</td>\n",
              "      <td>0.008416</td>\n",
              "      <td>-0.041062</td>\n",
              "      <td>-0.087567</td>\n",
              "      <td>-0.117191</td>\n",
              "      <td>-0.205635</td>\n",
              "      <td>0.138599</td>\n",
              "      <td>0.158476</td>\n",
              "      <td>0.010989</td>\n",
              "      <td>0.126529</td>\n",
              "      <td>-0.165656</td>\n",
              "      <td>0.145881</td>\n",
              "      <td>-0.077725</td>\n",
              "      <td>-0.030732</td>\n",
              "      <td>-0.107863</td>\n",
              "      <td>0.134263</td>\n",
              "      <td>-0.069149</td>\n",
              "      <td>-0.114707</td>\n",
              "      <td>0.028937</td>\n",
              "      <td>0.115014</td>\n",
              "      <td>0.099640</td>\n",
              "      <td>-0.103545</td>\n",
              "      <td>0.010271</td>\n",
              "      <td>-0.108715</td>\n",
              "      <td>-0.156782</td>\n",
              "      <td>0.057225</td>\n",
              "      <td>0.019538</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 300 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "           0         1         2    ...       297       298       299\n",
              "5081 -0.081516  0.137667  0.047158  ... -0.082663 -0.114555  0.004344\n",
              "5758 -0.052561  0.190063 -0.074788  ...  0.007629 -0.010521  0.036336\n",
              "1682  0.140874 -0.029021 -0.049915  ...  0.040557 -0.140717  0.082089\n",
              "5494 -0.227624  0.187711 -0.014611  ... -0.158389 -0.114203  0.151461\n",
              "5955 -0.163305  0.131606 -0.017082  ... -0.156782  0.057225  0.019538\n",
              "\n",
              "[5 rows x 300 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hab7itULCo2w",
        "colab_type": "text"
      },
      "source": [
        "# 3. Modelamiento"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o8bSuxN1Bg8T",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import f1_score\n",
        "\n",
        "def test_model(train, val, y_train, y_val):\n",
        "    svmodel = svm.SVC()\n",
        "    svmodel.fit(train,y_train)\n",
        "\n",
        "    predictions = svmodel.predict(val)\n",
        "    print(\"Accuracy Score -> \",accuracy_score(predictions, y_val)*100)\n",
        "    print(\"F1 Score -> \",f1_score(predictions, y_val)*100)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ib9x8RFoCwP7",
        "colab_type": "code",
        "outputId": "f013f492-4cdf-45ab-ad91-9244a1f8907b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_model(X_train_we, X_val_we, y_train, y_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score ->  82.27183191070256\n",
            "F1 Score ->  77.46243739565944\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kftyqZ4vHjll",
        "colab_type": "text"
      },
      "source": [
        "**¿Que pasa con las palabras fuera del vocabulario?**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Z0Y7GaZEcESX",
        "colab_type": "code",
        "outputId": "6610f425-90c7-4922-9967-a59427c29989",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        }
      },
      "source": [
        "doc = nlp('@usatoday')\n",
        "for token in doc: print(token.text, token.has_vector, token.vector_norm,token.is_oov)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "@usatoday False 0.0 True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5GqhV-EpYhsj",
        "colab_type": "text"
      },
      "source": [
        "# 4. Entrenamiento de vectores desde cero"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sqs_V-Y4IVXY",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def tokenizer(text):\n",
        "  doc = nlp(text)\n",
        "  tokens = [token.text for token in doc]\n",
        "  return tokens"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "E60Vy8TbZyxo",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "sents = df_disaster.text.apply(tokenizer)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TsycMa5AaJPO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from gensim.models import Word2Vec"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-wHx8hYZ4K_",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model = Word2Vec(sents, min_count=3, size=100, window=5, sg=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MPZxVS21qozN",
        "colab_type": "text"
      },
      "source": [
        ""
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EPW09XQsabt5",
        "colab_type": "code",
        "outputId": "75dd982b-9fae-4737-a8c7-7d41cd4ef434",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 173
        }
      },
      "source": [
        "print(model.similarity('man', 'woman'))\n",
        "print(model.similarity('King', 'Queen'))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "0.98032683\n",
            "0.8026181\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n",
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `similarity` (Method will be removed in 4.0.0, use self.wv.similarity() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "p5uBXq8Pbpil",
        "colab_type": "code",
        "outputId": "1c1e35a9-f459-4a02-9070-2900a5efd248",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 275
        }
      },
      "source": [
        "model.most_similar('@usatoday')"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:1: DeprecationWarning: Call to deprecated `most_similar` (Method will be removed in 4.0.0, use self.wv.most_similar() instead).\n",
            "  \"\"\"Entry point for launching an IPython kernel.\n",
            "/usr/local/lib/python3.6/dist-packages/gensim/matutils.py:737: FutureWarning: Conversion of the second argument of issubdtype from `int` to `np.signedinteger` is deprecated. In future, it will be treated as `np.int64 == np.dtype(int).type`.\n",
            "  if np.issubdtype(vec.dtype, np.int):\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('Case', 0.9983925819396973),\n",
              " ('units', 0.9983007907867432),\n",
              " ('min', 0.9982388019561768),\n",
              " ('MIDO', 0.9982192516326904),\n",
              " ('Travel', 0.9981244802474976),\n",
              " ('Navy', 0.9981186389923096),\n",
              " ('Dramatic', 0.9981140494346619),\n",
              " ('Newest', 0.9980981945991516),\n",
              " ('Route', 0.9980724453926086),\n",
              " ('Complex', 0.9980449676513672)]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 159
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xGkdTQSfc-Lm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def document_vector(sent):\n",
        "  word_vectors = [model[token] if token in model.wv else np.zeros(100) for token in sent]\n",
        "  return np.asarray(word_vectors).mean(axis=0) "
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yADFf_-ugDJV",
        "colab_type": "code",
        "outputId": "72d64043-558c-4979-b6e0-51e8a2dbf3bf",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 71
        }
      },
      "source": [
        "X_train_sents = X_train.apply(tokenizer)\n",
        "X_val_sents = X_val.apply(tokenizer)\n",
        "\n",
        "X_train_w2v = [document_vector(sent) for sent in X_train_sents]\n",
        "X_val_w2v = [document_vector(sent) for sent in X_val_sents]\n",
        "\n",
        "X_train_w2v = np.stack(X_train_w2v)\n",
        "X_val_w2v = np.stack((X_val_w2v))"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/ipykernel_launcher.py:2: DeprecationWarning: Call to deprecated `__getitem__` (Method will be removed in 4.0.0, use self.wv.__getitem__() instead).\n",
            "  \n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJI6pD0Xg7g1",
        "colab_type": "code",
        "outputId": "96b4f05c-d617-440c-fc82-1d75108d784b",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        }
      },
      "source": [
        "test_model(X_train_w2v, X_val_w2v, y_train, y_val)"
      ],
      "execution_count": 0,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Accuracy Score ->  73.60472751149048\n",
            "F1 Score ->  63.52087114337568\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}